{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c2311b",
   "metadata": {},
   "source": [
    "# 15-minute-city analysis in Graz, Austria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b76ba5",
   "metadata": {},
   "source": [
    "### GIS analysis techniques 2: Final project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d8becc",
   "metadata": {},
   "source": [
    "Kornelia Birkle, Vita Duit, Timon Wutte, Florian Zaar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94b4813",
   "metadata": {},
   "source": [
    "A reproducible workflow to find served and underserved areas in a 15-minute-city frame and suggestions for new facilities to expand the 15-minute-city."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ae15ab",
   "metadata": {},
   "source": [
    "### Content:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d34130",
   "metadata": {},
   "source": [
    "##### Data integration:\n",
    "- city boundaries of Graz\n",
    "- street network of Graz and surrounding area within 1000m\n",
    "- POIs in Graz and surrounding area withing 1000m: \n",
    "  public transport stations, supermarkets, green spaces, pharmacies, doctors\n",
    "- population of Graz for the year 2020 (100x100m grid)\n",
    "- buildings of Graz\n",
    "- residential areas of Graz\n",
    "##### Data management:\n",
    "- Data cleaning\n",
    "- Building POI dataset with consistent columns, categorised by type of POI\n",
    "\n",
    "##### Network analysis:\n",
    "- Routing from all POIs to network nodes with cutoff 1000m (15 minutes on foot)\n",
    "- Find nodes with all 5 POI types (\"served areas\")\n",
    "- Accessibility statistics of population and area within served areas\n",
    "\n",
    "##### Scenario: Expand 15-minute-city by adding facilities\n",
    "- Find nodes with 4 of 5 POI types\n",
    "- Cluster these nodes with DBSCAN\n",
    "- Assign new facilities in centroids of these clusters\n",
    "- Recalculate accessibility statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7410ede",
   "metadata": {},
   "source": [
    "#### Data sources:\n",
    "- City Boundaries:\n",
    "OpenStreetMap contributors (2025). OpenStreetMap database (city & District Boundaries). Retrieved December 22, 2025, from https://www.openstreetmap.org\n",
    "- Street Network:\n",
    "OpenStreetMap contributors (2025). OpenStreetMap database (Street Network). Retrieved December 23, 2025, from https://www.openstreetmap.org\n",
    "- POIs:\n",
    "OpenStreetMap contributors. (2025). OpenStreetMap database (POI). Retrieved December 25, 2025, from https://www.openstreetmap.org\n",
    "- Population 2020 (100m grid):\n",
    "Pesaresi, M., Schiavina, M., Politis, P., Freire, S., Krasnodębska, K., Uhl, J. H., Carioli, A., Corbane, C., Dijkstra, L., Florio, P., Friedrich, H. K., Gao, J., Leyk, S., Lu, L., Maffenini, L., Mari-Rivero, I., Melchiorri, M., Syrris, V., Van Den Hoek, J., & Kemper, T. (2023). GHS-POP R2023A — GHS population grid multitemporal (1975–2030). Dataset: GHS_POP_E2020_GLOBE_R2023A_54009_100_V1_0_R4_C20. European Commission, Joint Research Centre. https://doi.org/10.2905/2FF68A52-5B5B-4A22-8F40-C41DA8332CFE. Available under: https://human-settlement.emergency.copernicus.eu/download.php?ds=pop\n",
    "- Buildings:\n",
    "OpenStreetMap contributors (2025). OpenStreetMap database (Buildings). Retrieved December 26, 2025, from https://www.openstreetmap.org\n",
    "- Residential Areas:\n",
    "OpenStreetMap contributors (2025). OpenStreetMap database (Residential). Retrieved December 26, 2025, from https://www.openstreetmap.org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32741417",
   "metadata": {},
   "source": [
    "## Imports and pip installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0151f707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install osmnx rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ece9a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54c2390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "from scipy.interpolate import griddata\n",
    "from shapely.geometry import Point, Polygon, box\n",
    "from collections import defaultdict\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "import copy\n",
    "import pyarrow\n",
    "from sklearn.cluster import DBSCAN\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11758505",
   "metadata": {},
   "source": [
    "#### Definitions of paths and project variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c2f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(\".\")\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "POP_RAW_PATH = BASE_DIR / \"GHS_POP_E2020_GLOBE_R2023A_54009_100_V1_0_R4_C20.tif\" # adjust this path after downloading\n",
    "POP_GRAZ_PATH = \"preprocessed/graz_population.tif\"\n",
    "GRAPH_PATH = DATA_DIR / \"graz_street_network_buffer1km.graphml\"\n",
    "EDGE_PATH = DATA_DIR / \"graz_street_network_edges.parquet\"\n",
    "NODE_PATH = DATA_DIR / \"graz_street_network_nodes.parquet\"\n",
    "POI_PATH = DATA_DIR / \"graz_pois.parquet\"\n",
    "GREEN_SPACES_PATH = DATA_DIR / \"graz_green_spaces_raw.parquet\"\n",
    "ACCESS_POINTS_PATH = DATA_DIR / \"graz_green_access_points.parquet\"\n",
    "RESIDENTIAL_PATH = DATA_DIR / \"graz_residential_areas.parquet\"\n",
    "BUILDINGS_PATH = DATA_DIR / \"graz_buildings.parquet\"\n",
    "POI_ALL_PATH = DATA_DIR / \"graz_pois_all.parquet\"\n",
    "POI_ALL_POINTS_PATH = DATA_DIR / \"graz_pois_all_points.parquet\"\n",
    "\n",
    "\n",
    "\n",
    "project_crs = 31256  # MGI / Austria GK East"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca09e92",
   "metadata": {},
   "source": [
    "## Data integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0760bf82",
   "metadata": {},
   "source": [
    "For the 15-minute-city analysis, open data sources are used. Street network, residential areas and POIs (facilities) are taken from OSM, the population grid (100m x 100m) from Global Human Settlement Layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f6eb21",
   "metadata": {},
   "source": [
    "#### Load city boundary of Graz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f1e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define place name\n",
    "place_name:str = \"Graz, Austria\"\n",
    "\n",
    "# get the boundary polygon of Graz\n",
    "gdf_graz = ox.geocode_to_gdf(place_name)\n",
    "\n",
    "# change CRS to EPSG: 31256\n",
    "gdf_graz = gdf_graz.to_crs(epsg=project_crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb4989b",
   "metadata": {},
   "source": [
    "#### Load district boundaries of Graz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919468a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get districts of Graz\n",
    "gdf_districts = ox.features_from_place(place_name, tags={'admin_level': '9'})\n",
    "\n",
    "# filter to get only polygons and reproject\n",
    "gdf_districts = gdf_districts[gdf_districts.geometry.type.isin(['Polygon', 'MultiPolygon'])]\n",
    "gdf_districts = gdf_districts.to_crs(epsg=project_crs)\n",
    "\n",
    "# drop all columns except 'name' and 'geometry'\n",
    "gdf_districts = gdf_districts[['name', 'geometry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b171e52f",
   "metadata": {},
   "source": [
    "#### Load street network of Graz and 1000m beyond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1295b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buffer (1000m) boundary of Graz to include streets and POIs just outside the city limits\n",
    "buffered_poly_31256 = gdf_graz.geometry.iloc[0].buffer(1000)\n",
    "\n",
    "# reproject buffer for osmnx (WGS84)\n",
    "buffered_poly_wgs84 = (\n",
    "    gpd.GeoSeries([buffered_poly_31256], crs=f\"EPSG:{project_crs}\")\n",
    "    .to_crs(\"EPSG:4326\")\n",
    "    .iloc[0]\n",
    ")\n",
    "\n",
    "# load pre-saved street network and nodes/edges GeoDataFrames if they exist, otherwise create and save them\n",
    "try:\n",
    "    edges = gpd.read_parquet(EDGE_PATH)\n",
    "    nodes = gpd.read_parquet(NODE_PATH)\n",
    "    network_graz = ox.load_graphml(GRAPH_PATH)\n",
    "except:\n",
    "    # load street network in buffered polygon, network_type = 'walk'\n",
    "    \n",
    "    G = ox.graph_from_polygon(\n",
    "        buffered_poly_wgs84,\n",
    "        network_type=\"walk\",\n",
    "        simplify=True\n",
    "    )\n",
    "\n",
    "    # reproject to project crs\n",
    "    G = ox.project_graph(G, to_crs=f\"EPSG:{project_crs}\")\n",
    "    ox.save_graphml(G, filepath=GRAPH_PATH)\n",
    "    network_graz = ox.load_graphml(GRAPH_PATH)\n",
    "\n",
    "    # convert street network graphs into two GeoDataFrames\n",
    "    nodes_raw, edges_raw = ox.graph_to_gdfs(G, nodes=True, edges=True)\n",
    "\n",
    "    # remove list columns\n",
    "    def drop_list_columns(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "        list_cols = [\n",
    "            c for c in gdf.columns\n",
    "            if c != \"geometry\" and gdf[c].apply(lambda x: isinstance(x, list)).any()\n",
    "        ]\n",
    "        return gdf.drop(columns=list_cols)\n",
    "\n",
    "    edges_clean = drop_list_columns(edges_raw)\n",
    "    nodes_clean = drop_list_columns(nodes_raw)\n",
    "\n",
    "    # save as GeoParquet\n",
    "    edges_clean.to_parquet(EDGE_PATH, index=False)\n",
    "    nodes_clean.to_parquet(NODE_PATH, index=False)\n",
    "    edges = gpd.read_parquet(EDGE_PATH)\n",
    "    nodes = gpd.read_parquet(NODE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39252a0",
   "metadata": {},
   "source": [
    "Quick overview map: Plot nodes, edges and boundary of Graz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afb74b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = edges.plot(figsize=(8, 8), linewidth=0.4, color=\"grey\")\n",
    "nodes.plot(ax=ax, markersize=1, color=\"red\")\n",
    "\n",
    "gdf_graz.boundary.plot(ax=ax, edgecolor=\"black\", linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67695b18",
   "metadata": {},
   "source": [
    "##### Load residential areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c39765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get residential areas of Graz\n",
    "gdf_residential_raw = ox.features_from_place(place_name, tags={\"landuse\": \"residential\"})\n",
    "gdf_residential = gdf_residential_raw.to_crs(epsg=31256)\n",
    "\n",
    "gdf_residential = gdf_residential.dissolve()\n",
    "\n",
    "gdf_residential = gpd.overlay(gdf_residential, gdf_graz, how='intersection')\n",
    "\n",
    "# Save residential areas as GeoParquet\n",
    "gdf_residential.to_parquet(RESIDENTIAL_PATH, index=False) \n",
    "gdf_residential = gpd.read_parquet(RESIDENTIAL_PATH)\n",
    "gdf_residential = gdf_residential.to_crs(epsg=project_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c799d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gdf_graz.boundary.plot(edgecolor=\"black\", figsize=(6, 6))\n",
    "\n",
    "gdf_residential.plot(\n",
    "    ax=ax,\n",
    "    color=\"orange\",\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "plt.title(\"residential areas in Graz\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15580fec",
   "metadata": {},
   "source": [
    "##### Load population grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4519a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the preprocessed population grid for Graz exists, otherwise create it\n",
    "try: \n",
    "    with rasterio.open(POP_GRAZ_PATH) as dataset:\n",
    "        graz_pop = dataset.read(1)\n",
    "except:\n",
    "    # open grid data set (population grid)\n",
    "    src = rasterio.open(POP_RAW_PATH)\n",
    "    #print(src.crs)\n",
    "\n",
    "    # project Graz border into grid CRS (ESRI: 54009)\n",
    "    graz_geom = gdf_graz.to_crs(src.crs).geometry.iloc[0]\n",
    "\n",
    "    # mask grid with Graz geometry (pixels outside Graz are removed)\n",
    "    out_img, out_transform = mask(\n",
    "        dataset=src,\n",
    "        shapes=[graz_geom],\n",
    "        crop=True\n",
    "    )\n",
    "    # copy metadata from the original grid and adjust metadata to the cropped grid\n",
    "    out_meta = src.meta.copy()\n",
    "    out_meta.update({\n",
    "        \"height\": out_img.shape[1],\n",
    "        \"width\":  out_img.shape[2],\n",
    "        \"transform\": out_transform\n",
    "    })\n",
    "    # write and save a new grid\n",
    "    with rasterio.open(POP_GRAZ_PATH, \"w\", **out_meta) as dst:\n",
    "        dst.write(out_img)\n",
    "    \n",
    "    with rasterio.open(POP_GRAZ_PATH) as dataset:\n",
    "        graz_pop = dataset.read(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ac9a8a",
   "metadata": {},
   "source": [
    "Visualization for quick overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610e1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(graz_pop, cmap=\"gray\")\n",
    "plt.title(\"Graz Population (GHSL)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae255f7",
   "metadata": {},
   "source": [
    "#### Load POIs in Graz and immediate surrounding area\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb63e6af",
   "metadata": {},
   "source": [
    "POIs considered necessary in daily life (should be within 15-minute walking distance): \n",
    "- public transport stations (bus and tram stops)\n",
    "- supermarkets\n",
    "- green spaces\n",
    "- pharmacies\n",
    "- doctors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c09292",
   "metadata": {},
   "source": [
    "##### Define POI tags for OSM query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebe3a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {\n",
    "    # public transport stations & stops\n",
    "    \"highway\": [\"platform\", \"bus_stop\"],\n",
    "    \"public_transport\": [\"platform\", \"stop_position\"],\n",
    "    \"railway\": [\"tram_stop\"],\n",
    "\n",
    "    # supermarkets\n",
    "    \"shop\": [\"supermarket\", \"chemist\"],\n",
    "\n",
    "    # pharmacies & doctors\n",
    "    \"amenity\": [\"doctors\", \"pharmacy\"],\n",
    "}\n",
    "\n",
    "# Green spaces are defined separately for preprocessing\n",
    "tags_green_spaces = {\n",
    "    # green spaces\n",
    "    \"leisure\": [\"park\", \"garden\", \"recreation_ground\"],\n",
    "    \"landuse\": [\"forest\", \"recreation_ground\", \"cemetery\"],\n",
    "    \"natural\": [\"wood\"],\n",
    "    \"amenity\": [\"park\", \"playground\", \"graveyard\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c739dc7f",
   "metadata": {},
   "source": [
    "##### Load public transport stations, supermarkets, pharmacies and doctors from OSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abead69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois = ox.features_from_polygon(buffered_poly_wgs84, tags=tags) # osmnx sends a request to the Overpass API\n",
    "pois = pois.to_crs(f\"EPSG:{project_crs}\")\n",
    "pois = pois.to_parquet(POI_PATH, index=False)\n",
    "pois = gpd.read_parquet(POI_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ebd6ba",
   "metadata": {},
   "source": [
    "##### Load green spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539caa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query raw green spaces once\n",
    "green_spaces_raw = ox.features_from_polygon(buffered_poly_wgs84, tags=tags_green_spaces)\n",
    "green_spaces_raw = green_spaces_raw.to_crs(f\"EPSG:{project_crs}\")\n",
    "\n",
    "# Save as GeoParquet\n",
    "green_spaces_raw.to_parquet(GREEN_SPACES_PATH, index=False)\n",
    "green_spaces = gpd.read_parquet(GREEN_SPACES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbb4f0f",
   "metadata": {},
   "source": [
    "## Data management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08d6c62",
   "metadata": {},
   "source": [
    "The data for the POIs has to be prepared for the 15-minute-city analysis, making sure there are only point geometries in the dataset and categorizing the POIs into POI types. They also have to be snapped to nearest nodes in the street network for the routing in the network analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356951df",
   "metadata": {},
   "source": [
    "##### Non-public green spaces and green spaces within 50 meters of major roads are excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addeba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop private gardens without name\n",
    "green_spaces = green_spaces[~((green_spaces[\"leisure\"] == \"garden\") & (green_spaces[\"name\"].isna()))]\n",
    "\n",
    "# Exclude public green spaces that are marked as 'no' or 'private' access\n",
    "green_spaces = green_spaces[green_spaces['access'].isna() | green_spaces['access'].isin(['yes', 'permissive'])]\n",
    "\n",
    "# Exclude green spaces smaller than 1 ha\n",
    "green_spaces = green_spaces[green_spaces.geometry.area >= 10000]\n",
    "\n",
    "# Exclude green spaces within 50m of major roads (highways and trunks)\n",
    "# Download Highways and trunks in Graz from osmnx\n",
    "highways = ox.features_from_place(\n",
    "    place_name,\n",
    "    tags={\"highway\": [\"motorway\", \"trunk\"]}\n",
    ")\n",
    "highways = highways.to_crs(epsg=project_crs)\n",
    "highways = highways[highways['tunnel'] != 'yes']\n",
    "\n",
    "#create buffer of 50 meters around highways\n",
    "highway_buffer = highways.buffer(50)\n",
    "green_spaces = green_spaces[~green_spaces.geometry.intersects(highway_buffer.unary_union)]\n",
    "\n",
    "# Dissolve green spaces\n",
    "green_spaces = green_spaces.dissolve(as_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c87cfd2",
   "metadata": {},
   "source": [
    "##### Calculate access points to green spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9661f3",
   "metadata": {},
   "source": [
    "Since green spaces are usually polygon geometry, they are intersected with the edges in the network to calculate access points (point geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ceefdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract boundaries of parks as LineStrings\n",
    "park_boundaries = green_spaces.unary_union.boundary  # Get the actual geometry\n",
    "\n",
    "# Create a list to store access points\n",
    "access_points_list = []\n",
    "\n",
    "# Iterate through each edge and find intersections with park boundaries\n",
    "for idx, edge in edges.iterrows():\n",
    "    intersection = edge.geometry.intersection(park_boundaries)\n",
    "    \n",
    "    if not intersection.is_empty:\n",
    "        if intersection.geom_type == 'Point':\n",
    "            access_points_list.append(intersection)\n",
    "        elif intersection.geom_type == 'MultiPoint':\n",
    "            access_points_list.extend(list(intersection.geoms))\n",
    "        elif intersection.geom_type == 'LineString':\n",
    "            access_points_list.extend([Point(intersection.coords[0]), Point(intersection.coords[-1])\n",
    "    ])\n",
    "\n",
    "# Create GeoDataFrame of access points\n",
    "access_points = gpd.GeoDataFrame(\n",
    "    geometry=access_points_list,\n",
    "    crs=edges.crs\n",
    ")\n",
    "\n",
    "# Remove duplicates\n",
    "access_points = access_points.drop_duplicates(subset=['geometry'])\n",
    "\n",
    "print(f\"Found {len(access_points)} access points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19eea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save access points as GeoParquet\n",
    "access_points.to_parquet(ACCESS_POINTS_PATH, index=False)\n",
    "access_points = gpd.read_parquet(ACCESS_POINTS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45dd135",
   "metadata": {},
   "source": [
    "##### Put together all POIs into one dataset with consistent columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c75ac",
   "metadata": {},
   "source": [
    "For the 15-minute analysis, the POIs should all be in one dataset, distinguished by their analysis_type (public transport, supermarket, green space, pharmacy, doctor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e95d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize columns\n",
    "pois[\"poi_group\"] = pd.Series(index=pois.index, dtype=\"string\")\n",
    "pois[\"poi_subtype\"] = pd.Series(index=pois.index, dtype=\"string\")\n",
    "pois[\"analysis_type\"] = pd.Series(index=pois.index, dtype=\"string\") # For 15-minute analysis\n",
    "\n",
    "\n",
    "# TRANSPORT\n",
    "# Filter for POI group 'transport'\n",
    "transport_mask = (\n",
    "    pois[\"highway\"].isin([\"platform\", \"bus_stop\"])\n",
    "    | pois[\"public_transport\"].isin([\"platform\", \"stop_position\"])\n",
    "    | pois[\"railway\"].isin([\"tram_stop\"])\n",
    ")\n",
    "pois.loc[transport_mask, \"poi_group\"] = \"transport\"\n",
    "\n",
    "# Fill in tags as subtype\n",
    "transport_tags = (\n",
    "    pois.loc[transport_mask, [\"highway\", \"public_transport\", \"railway\"]]\n",
    "    .astype(\"string\")\n",
    "    .replace(\"nan\", pd.NA)\n",
    "    .bfill(axis=1)\n",
    "    .iloc[:, 0]\n",
    ")\n",
    "pois.loc[transport_mask, \"poi_subtype\"] = transport_tags\n",
    "pois.loc[transport_mask, \"analysis_type\"] = \"public_transport\"\n",
    "\n",
    "\n",
    "# SHOP\n",
    "shop_mask = pois[\"shop\"].isin([\"supermarket\", \"chemist\"])\n",
    "pois.loc[shop_mask, \"poi_group\"] = \"shop\"\n",
    "pois.loc[shop_mask, \"poi_subtype\"] = pois.loc[shop_mask, \"shop\"]\n",
    "pois.loc[shop_mask, \"analysis_type\"] = \"shop\"\n",
    "\n",
    "\n",
    "# MEDICAL\n",
    "medical_values = [\"doctors\", \"pharmacy\"]\n",
    "med_mask = pois[\"amenity\"].isin(medical_values)\n",
    "pois.loc[med_mask, \"poi_group\"] = \"medical\"\n",
    "pois.loc[med_mask, \"poi_subtype\"] = pois.loc[med_mask, \"amenity\"]\n",
    "\n",
    "# distinguish doctor vs pharmacy for analysis_type\n",
    "pois.loc[med_mask & (pois[\"amenity\"] == \"doctors\"), \"analysis_type\"] = \"doctor\"\n",
    "pois.loc[med_mask & (pois[\"amenity\"] == \"pharmacy\"), \"analysis_type\"] = \"pharmacy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f2054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add green spaces access points to POIs\n",
    "access_points[\"poi_group\"] = \"green_space\"\n",
    "access_points[\"poi_subtype\"] = \"access_point\"\n",
    "access_points[\"analysis_type\"] = \"green_space\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2130c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all POIs including green access points into a single GeoParquet\n",
    "\n",
    "# Make sure both in same CRS\n",
    "access_points = access_points.to_crs(pois.crs)\n",
    "\n",
    "# Ensure both have the same columns\n",
    "all_cols = sorted(set(pois.columns) | set(access_points.columns))\n",
    "\n",
    "pois_all = pd.concat(\n",
    "    [\n",
    "        pois.reindex(columns=all_cols),\n",
    "        access_points.reindex(columns=all_cols),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "pois_all.to_parquet(POI_ALL_PATH, index=False)\n",
    "pois_all = gpd.read_parquet(POI_ALL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77881784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop redundant columns\n",
    "pois_all = pois_all[['geometry', 'poi_group', 'poi_subtype', 'analysis_type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2bdfdc",
   "metadata": {},
   "source": [
    "##### Snap all POIs to nearest nodes for routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9ec781",
   "metadata": {},
   "source": [
    "Before snapping the POIs to their nearest nodes, it has to be made sure that there are only point geometries in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc1139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_all_points = pois_all.copy()\n",
    "\n",
    "# Convert LineString and Polygon/MultiPolygon to representative points\n",
    "mask_non_point = pois_all_points.geometry.geom_type.isin([\"LineString\", \"Polygon\", \"MultiPolygon\"])\n",
    "\n",
    "# record source of geometry\n",
    "pois_all_points[\"geom_source\"] = \"original_point\"\n",
    "pois_all_points.loc[mask_non_point, \"geom_source\"] = \"representative_point\"\n",
    "\n",
    "# representative_point() is safer than centroid; guaranteed inside polygon\n",
    "pois_all_points.loc[mask_non_point, \"geometry\"] = (\n",
    "    pois_all_points.loc[mask_non_point, \"geometry\"].representative_point()\n",
    ")\n",
    "\n",
    "# Save to Geo Parquet\n",
    "pois_all_points.to_parquet(POI_ALL_POINTS_PATH, index=False)\n",
    "pois_all_points = gpd.read_parquet(POI_ALL_POINTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c40375",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_all_points = pois_all_points.to_crs(epsg=project_crs)\n",
    "\n",
    "# Coordinates of POIs\n",
    "X = pois_all_points.geometry.x  # x/longitude or projected x\n",
    "Y = pois_all_points.geometry.y  # y/latitude or projected y\n",
    "# Nearest node for each POI\n",
    "nearest_nodes = ox.distance.nearest_nodes(network_graz, X, Y)\n",
    "pois_all_points[\"nearest_node\"] = nearest_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ec83bc",
   "metadata": {},
   "source": [
    "##### Quick overview map: Plot POIs per tag and boundary of Graz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef276421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots with poi_group and poi_subtype\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# 1) All public transport POIs by subtype (bus_stop, platform, tram_stop, station, halt)\n",
    "ax1_1 = axs[0, 0]\n",
    "mask_pt = pois_all_points[\"poi_group\"] == \"transport\"\n",
    "pois_all_points[mask_pt].plot(\n",
    "    ax=ax1_1,\n",
    "    column=\"poi_subtype\",\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    markersize=5,\n",
    ")\n",
    "gdf_graz.boundary.plot(ax=ax1_1, edgecolor=\"black\", linewidth=2)\n",
    "ax1_1.set_title(\"Public transport (subtypes)\")\n",
    "\n",
    "# 2) Shops by subtype (supermarket, chemist)\n",
    "ax1_2 = axs[0, 1]\n",
    "mask_shop = pois_all_points[\"poi_group\"] == \"shop\"\n",
    "pois_all_points[mask_shop].plot(\n",
    "    ax=ax1_2,\n",
    "    #column=\"poi_subtype\",\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    markersize=5,\n",
    ")\n",
    "gdf_graz.boundary.plot(ax=ax1_2, edgecolor=\"black\", linewidth=2)\n",
    "ax1_2.set_title(\"Supermarkets\")\n",
    "\n",
    "# 3) Medical POIs (doctors, hospital, clinic, pharmacy)\n",
    "ax1_3 = axs[0, 2]\n",
    "mask_med = pois_all_points[\"poi_group\"] == \"medical\"\n",
    "pois_all_points[mask_med].plot(\n",
    "    ax=ax1_3,\n",
    "    column=\"poi_subtype\",\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    markersize=5,\n",
    ")\n",
    "gdf_graz.boundary.plot(ax=ax1_3, edgecolor=\"black\", linewidth=2)\n",
    "ax1_3.set_title(\"Medical POIs (subtypes)\")\n",
    "\n",
    "# 4) All POIs by analysis group (transport / shop / doctor / pharmacy / green_space)\n",
    "ax2_1 = axs[1, 0]\n",
    "pois_all_points.plot(\n",
    "    ax=ax2_1,\n",
    "    column=\"poi_group\",\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    markersize=5,\n",
    ")\n",
    "gdf_graz.boundary.plot(ax=ax2_1, edgecolor=\"black\", linewidth=2)\n",
    "ax2_1.set_title(\"All POIs (groups)\")\n",
    "\n",
    "# 5) Green-space access points\n",
    "ax2_2 = axs[1, 1]\n",
    "mask_green = pois_all_points[\"poi_group\"] == \"green_space\"\n",
    "pois_all_points[mask_green].plot(\n",
    "    ax=ax2_2,\n",
    "    column=\"poi_subtype\",   # e.g. 'access_point'\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    markersize=5,\n",
    ")\n",
    "gdf_graz.boundary.plot(ax=ax2_2, edgecolor=\"black\", linewidth=2)\n",
    "ax2_2.set_title(\"Green-space access\")\n",
    "\n",
    "# 6) Optional: all POIs again, but colored by subtype\n",
    "ax2_3 = axs[1, 2]\n",
    "pois_all_points.plot(\n",
    "    ax=ax2_3,\n",
    "    column=\"poi_subtype\",\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    markersize=5,\n",
    ")\n",
    "gdf_graz.boundary.plot(ax=ax2_3, edgecolor=\"black\", linewidth=2)\n",
    "ax2_3.set_title(\"All POIs (subtypes)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / \"pois_by_group_and_subtype.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e59f643",
   "metadata": {},
   "source": [
    "Quick overview: Display number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1766b9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POI analysis types\n",
    "analysis_types = pois_all_points[\"analysis_type\"].value_counts(dropna=False)\n",
    "plt.figure(figsize=(8, 6))\n",
    "analysis_types.plot(kind='bar')\n",
    "plt.title(\"POI Analysis Types\")\n",
    "plt.xlabel(\"Analysis Type\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / \"poi_analysis_types.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19546982",
   "metadata": {},
   "source": [
    "## Network analysis: 15-minute walking distance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f969d3cb",
   "metadata": {},
   "source": [
    "For each node in the city network, it should be found which POIs can be reached within 1000m walking distance. 1000m is considered as a 15-minute walk (with 4 km/h). Nodes with all 5 POI types within 1000m walking distance are considered to be in a served area, nodes with less than 5 POI types accessible are in an underserved area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cea7d3",
   "metadata": {},
   "source": [
    "#### Only keep POIs with nearest node & create lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2504e6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep POIs that have a nearest_node\n",
    "pois_routable = pois_all_points[pois_all_points[\"nearest_node\"].notna()].copy()\n",
    "\n",
    "# group by node and subtype\n",
    "poi_by_node_and_type = (\n",
    "    pois_routable.groupby([\"nearest_node\", \"analysis_type\"])\n",
    "    .size()\n",
    "    .rename(\"poi_count\")\n",
    "    .reset_index()\n",
    ")\n",
    "print(poi_by_node_and_type.head())\n",
    "\n",
    "# Create easier lookup\n",
    "node_to_types = defaultdict(set)\n",
    "for row in poi_by_node_and_type.itertuples(index=False):\n",
    "    node_to_types[row.nearest_node].add(row.analysis_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46aa3ff",
   "metadata": {},
   "source": [
    "##### Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59380f35",
   "metadata": {},
   "source": [
    "For the routing, a single-source Dijkstra's algorithm is used with a cutoff distance of 1000m to find the reachable POI types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DIST = 1000  # maximum walking distance in meters\n",
    "\n",
    "\n",
    "# Routing with Dijkstra's algorithm\n",
    "\n",
    "print(f\"Calculating accessibility from {len(node_to_types)} POI nodes...\")\n",
    "\n",
    "node_coverage = defaultdict(set)  # node_id -> set of reachable analysis_type within 1km\n",
    "\n",
    "for poi_node, poi_types in node_to_types.items():\n",
    "    try:\n",
    "        # Calculate distances from this POI node to all reachable nodes\n",
    "        lengths = nx.single_source_dijkstra_path_length(\n",
    "            network_graz,\n",
    "            source=poi_node,\n",
    "            weight=\"length\",\n",
    "            cutoff=MAX_DIST,\n",
    "        )\n",
    "        \n",
    "        # For each reachable node, add all POI types available at this POI node\n",
    "        for reachable_node in lengths.keys():\n",
    "            node_coverage[reachable_node] |= poi_types\n",
    "            \n",
    "    except nx.NodeNotFound:\n",
    "        print(f\"Warning: POI node {poi_node} not found in network\")\n",
    "        continue\n",
    "\n",
    "# Convert defaultdict to regular dict for compatibility with your existing code\n",
    "node_coverage = dict(node_coverage)\n",
    "\n",
    "print(f\"Calculated accessibility for {len(node_coverage)} network nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430516dc",
   "metadata": {},
   "source": [
    "##### Find reachable POI types within 1km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ea1956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use nodes from network graph for saving the analysis\n",
    "nodes_analysis, edges_analysis = ox.graph_to_gdfs(network_graz, nodes=True, edges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460d9429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find reachable types\n",
    "nodes_analysis[\"reachable_types\"] = nodes_analysis.index.map(\n",
    "    lambda n: node_coverage.get(n, set())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbd9af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign POI types required within 1km here\n",
    "required_types = {\n",
    "    \"shop\",\n",
    "    \"public_transport\",\n",
    "    \"green_space\",\n",
    "    \"pharmacy\",\n",
    "    \"doctor\"\n",
    "}\n",
    "\n",
    "# Column indicating for each node if all required types are reachable within 1 km (Boolean)\n",
    "nodes_analysis[\"has_all_required\"] = nodes_analysis[\"reachable_types\"].apply(\n",
    "    lambda s: required_types.issubset(s)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933aeb46",
   "metadata": {},
   "source": [
    "##### Clip to residential areas for scenario analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee44a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New df with only nodes within residential areas\n",
    "nodes_analysis_residential = gpd.clip(nodes_analysis, gdf_residential).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd93cb4",
   "metadata": {},
   "source": [
    "## Results of network analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081396d2",
   "metadata": {},
   "source": [
    "##### Visualize nodes by whether they have all 5 POI types accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7d82cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot nodes in residential areas by whether they have all required POI types within 1 km\n",
    "\n",
    "ax = gdf_graz.boundary.plot(edgecolor=\"black\", figsize=(8, 8))\n",
    "# plot gdf_residential boundary\n",
    "gdf_residential.boundary.plot(ax=ax, edgecolor=\"orange\", linewidth=1)\n",
    "\n",
    "nodes_analysis_residential.plot(\n",
    "    ax=ax,\n",
    "    column=\"has_all_required\",\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    markersize=3,\n",
    ")\n",
    "\n",
    "ax.set_title(\"Nodes in residential areas with all POIs within 1 km\")\n",
    "plt.savefig(RESULTS_DIR / \"residential_nodes_with_all_pois.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b378c2",
   "metadata": {},
   "source": [
    "##### Visualize served and underserved areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce77029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare extent and grid\n",
    "minx, miny, maxx, maxy = gdf_graz.total_bounds\n",
    "\n",
    "resolution = 50  # grid cell resolution in meters; lower values have longer computation time\n",
    "x_coords = np.arange(minx, maxx, resolution)\n",
    "y_coords = np.arange(miny, maxy, resolution)\n",
    "xx, yy = np.meshgrid(x_coords, y_coords)\n",
    "\n",
    "# Prepare node points and boolean values\n",
    "# nodes: GeoDataFrame of network nodes with column 'has_all_required'\n",
    "node_points = np.array([[p.x, p.y] for p in nodes.geometry])\n",
    "node_access = nodes_analysis[\"has_all_required\"].astype(float).values  # True->1.0, False->0.0\n",
    "\n",
    "# Interpolate boolean (via nearest neighbour) onto grid\n",
    "print(\"Interpolating has_all_required across grid using nearest neighbor...\")\n",
    "grid_access_float = griddata(\n",
    "    node_points,\n",
    "    node_access,\n",
    "    (xx, yy),\n",
    "    method=\"nearest\"\n",
    ")\n",
    "\n",
    "# Convert back to boolean (NaN -> False)\n",
    "grid_access_bool = ~np.isnan(grid_access_float) & (grid_access_float >= 0.5)\n",
    "\n",
    "# Create grid polygons within Graz, attach boolean\n",
    "print(\"Creating grid cells...\")\n",
    "grid_polygons = []\n",
    "\n",
    "graz_geom = gdf_graz.geometry.iloc[0]\n",
    "\n",
    "for i in range(len(x_coords) - 1):\n",
    "    for j in range(len(y_coords) - 1):\n",
    "        cell = Polygon([\n",
    "            (x_coords[i],   y_coords[j]),\n",
    "            (x_coords[i+1], y_coords[j]),\n",
    "            (x_coords[i+1], y_coords[j+1]),\n",
    "            (x_coords[i],   y_coords[j+1]),\n",
    "        ])\n",
    "\n",
    "        if not graz_geom.intersects(cell):\n",
    "            continue\n",
    "\n",
    "        clipped_cell = cell.intersection(graz_geom)\n",
    "        if clipped_cell.is_empty or clipped_cell.area < 1:\n",
    "            continue\n",
    "\n",
    "        served = bool(grid_access_bool[j, i])\n",
    "\n",
    "        grid_polygons.append({\n",
    "            \"served\": served,            # True = within 15 min of all required services\n",
    "            \"geometry\": clipped_cell\n",
    "        })\n",
    "\n",
    "grid_gdf = gpd.GeoDataFrame(grid_polygons, crs=nodes.crs)\n",
    "print(f\"Created {len(grid_gdf)} grid cells within Graz\")\n",
    "\n",
    "# Area statistics\n",
    "grid_gdf[\"area_m2\"] = grid_gdf.geometry.area\n",
    "area_served = grid_gdf.loc[grid_gdf[\"served\"], \"area_m2\"].sum()\n",
    "area_total  = grid_gdf[\"area_m2\"].sum()\n",
    "share_area  = area_served / area_total\n",
    "print(\"Share of area within 15 min of all services:\", share_area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eb9248",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot grid, colored by served True/False\n",
    "grid_gdf.plot(\n",
    "    column=\"served\",\n",
    "    categorical=True,\n",
    "    cmap=\"YlGnBu\",       # blue = served, yellow = not\n",
    "    legend=True,\n",
    "    ax=ax,\n",
    "    edgecolor=\"none\"   \n",
    ")\n",
    "\n",
    "# Overlay Graz boundary\n",
    "gdf_graz.boundary.plot(ax=ax, color=\"black\", linewidth=1)\n",
    "\n",
    "ax.set_title(\"15-minute access to all required services\")\n",
    "ax.set_axis_off()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b62cfa",
   "metadata": {},
   "source": [
    "## Analysis: Population and area within the 15-minute-city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00bdae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pop_disaggregation(pop_grid, reachable_area):\n",
    "    \"\"\"\n",
    "    This function takes raster data containing population data and overlays polygon data to which the population data should be disaggregated to.\n",
    "    :param pop_grid: raster containing population data\n",
    "    :param reachable_area: area within the criteria of a 15-minute-city\n",
    "    \"\"\"\n",
    "    with rasterio.open(pop_grid) as src:\n",
    "        data = src.read(1)\n",
    "        transform = src.transform\n",
    "        nodata = src.nodata\n",
    "        masked = np.ma.masked_equal(data, nodata)\n",
    "        crs = src.crs\n",
    "        total_population = masked.sum()\n",
    "    \n",
    "    if reachable_area.crs != crs:\n",
    "        reachable_area = reachable_area.to_crs(crs)\n",
    "    \n",
    "    union_geom = reachable_area.loc[reachable_area[\"served\"]].geometry.union_all()\n",
    "\n",
    "    rows, cols = data.shape\n",
    "    cell_area = abs(transform.a * transform.e)\n",
    "\n",
    "    pop_within = 0.0\n",
    "    \n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            value = data[row, col]\n",
    "            if value == nodata or np.isnan(value):\n",
    "                continue\n",
    "            x1, y1 = rasterio.transform.xy(transform, row, col, offset=\"ul\")\n",
    "            x2, y2 = rasterio.transform.xy(transform, row, col, offset=\"lr\")\n",
    "            cell = box(x1, y2, x2, y1)\n",
    "            if not cell.intersects(union_geom):\n",
    "                continue\n",
    "            clipped = cell.intersection(union_geom)\n",
    "            if clipped.is_empty:\n",
    "                continue\n",
    "            weight = clipped.area / cell_area\n",
    "            pop_within += value * weight\n",
    "\n",
    "    pop_within_share = pop_within / total_population\n",
    "    \n",
    "    return round(pop_within), pop_within_share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb35185",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_graz_15min_city, share_pop_15min_city = pop_disaggregation(POP_GRAZ_PATH, grid_gdf)\n",
    "print(pop_graz_15min_city)\n",
    "print(share_pop_15min_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ffd479",
   "metadata": {},
   "source": [
    "## Scenario: Add facility to areas with 4 of 5 POIs covered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5205a9d0",
   "metadata": {},
   "source": [
    "Now we have found where the 15-minute-city is already implemented. The scenario analysis shows where it can be expanded by adding facilities to areas that are missing only 1 of the 5 POIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ace102",
   "metadata": {},
   "source": [
    "##### Find nodes with 4 of 5 POIs accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1712dc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add per-category coverage boolean columns\n",
    "nodes_analysis_residential[\"covered_shop\"] = nodes_analysis_residential[\"reachable_types\"].apply(\n",
    "    lambda s: \"shop\" in s\n",
    ")\n",
    "nodes_analysis_residential[\"covered_public_transport\"] = nodes_analysis_residential[\"reachable_types\"].apply(\n",
    "    lambda s: \"public_transport\" in s\n",
    ")\n",
    "nodes_analysis_residential[\"covered_green_space\"] = nodes_analysis_residential[\"reachable_types\"].apply(\n",
    "    lambda s: \"green_space\" in s\n",
    ")\n",
    "nodes_analysis_residential[\"covered_doctor\"] = nodes_analysis_residential[\"reachable_types\"].apply(\n",
    "    lambda s: \"doctor\" in s\n",
    ")\n",
    "nodes_analysis_residential[\"covered_pharmacy\"] = nodes_analysis_residential[\"reachable_types\"].apply(\n",
    "    lambda s: \"pharmacy\" in s\n",
    ")\n",
    "\n",
    "# number of covered categories\n",
    "nodes_analysis_residential[\"num_covered\"] = (\n",
    "    nodes_analysis_residential[\"covered_shop\"].astype(int)\n",
    "    + nodes_analysis_residential[\"covered_public_transport\"].astype(int)\n",
    "    + nodes_analysis_residential[\"covered_green_space\"].astype(int)\n",
    "    + nodes_analysis_residential[\"covered_doctor\"].astype(int)\n",
    "    + nodes_analysis_residential[\"covered_pharmacy\"].astype(int)\n",
    ")\n",
    "\n",
    "# consistency with has_all_required\n",
    "# nodes_analysis[\"has_all_required\"] = nodes_analysis[\"num_covered\"].eq(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d1a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save nodes with exactly 4 of 5 covered\n",
    "nodes_analysis_residential = nodes_analysis_residential[nodes_analysis_residential[\"num_covered\"] == 4].copy()\n",
    "nodes_analysis_residential[\"missing_type\"] = nodes_analysis_residential[\"reachable_types\"].apply(\n",
    "    lambda s: list(required_types - s)[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f2aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gdf_graz.boundary.plot(edgecolor=\"black\", figsize=(8, 8))\n",
    "gdf_residential.plot(\n",
    "    ax=ax, \n",
    "    facecolor=\"orange\", \n",
    "    edgecolor=\"orange\", \n",
    "    alpha=0.2,  # Transparency (0=fully transparent, 1=fully opaque)\n",
    "    linewidth=1\n",
    ")\n",
    "nodes_analysis_residential.plot(\n",
    "    ax=ax,\n",
    "    column=\"missing_type\",\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    markersize=3,\n",
    ")\n",
    "\n",
    "ax.set_title(\"Nodes with 4 of 5 POIs within 1 km\")\n",
    "\n",
    "plt.savefig(RESULTS_DIR / \"residential_nodes_with_4_of_5_pois.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abf314d",
   "metadata": {},
   "source": [
    "##### Cluster nodes with one missing POI with DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c03697",
   "metadata": {},
   "source": [
    "The nodes with 4 out of 5 POI types accessible are clustered to get areas with one missing facility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b6fae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split nodes by missing type\n",
    "\n",
    "types = nodes_analysis_residential[\"missing_type\"].unique()\n",
    "\n",
    "clusters_per_type = {}\n",
    "for t in types:\n",
    "    subset = nodes_analysis_residential[nodes_analysis_residential[\"missing_type\"] == t].copy()\n",
    "    clusters_per_type[t] = subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f959f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial clustering with DBSCAN\n",
    "\n",
    "eps = 400  # radius of the neighborhood in meters\n",
    "min_samples = 50  # minimum nr. of nodes to form a cluster, adjust this for different results!\n",
    "\n",
    "for t, g in clusters_per_type.items():\n",
    "    coords = np.vstack([g.geometry.x.values, g.geometry.y.values]).T  # Create coordinate stack for DBSCAN\n",
    "\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    labels = db.fit_predict(coords)   # -1 = noise\n",
    "\n",
    "    clusters_per_type[t][\"cluster_id\"] = labels  # which local cluster each node belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb904f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot clusters for each missing type\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "for i, (t, g) in enumerate(clusters_per_type.items()):\n",
    "    ax = axs[i // 2, i % 2]\n",
    "    gdf_graz.boundary.plot(ax=ax, edgecolor=\"black\", linewidth=1)\n",
    "\n",
    "    g.plot(\n",
    "        ax=ax,\n",
    "        column=\"cluster_id\",\n",
    "        categorical=True,\n",
    "        legend=True,\n",
    "        markersize=5,\n",
    "        cmap=\"tab20\"\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"Clusters of nodes missing '{t}'\")\n",
    "\n",
    "plt.savefig(RESULTS_DIR / \"clusters_missing_poi_types.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da49b79c",
   "metadata": {},
   "source": [
    "##### Find sites for the new facility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ed4cf2",
   "metadata": {},
   "source": [
    "Facilities are added to the nearest nodes of the centroids of the clusters missing one facility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61f709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_sites = []\n",
    "\n",
    "for t, g in clusters_per_type.items():\n",
    "    for cid, group in g[g[\"cluster_id\"] != -1].groupby(\"cluster_id\"):\n",
    "        # centroid of cluster\n",
    "        cx = group.geometry.x.mean()\n",
    "        cy = group.geometry.y.mean()\n",
    "\n",
    "        # choose node closest to centroid as candidate facility\n",
    "        d2 = (group.geometry.x - cx)**2 + (group.geometry.y - cy)**2\n",
    "        medoid_node = group.loc[d2.idxmin()]\n",
    "\n",
    "        candidate_sites.append({\n",
    "            \"missing_type\": t,\n",
    "            \"cluster_id\": cid,\n",
    "            \"node_id\": medoid_node.name,\n",
    "            \"geometry\": medoid_node.geometry,\n",
    "        })\n",
    "\n",
    "candidates_gdf = gpd.GeoDataFrame(candidate_sites, crs=project_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot candidate sites\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "gdf_graz.boundary.plot(ax=ax, edgecolor=\"black\")\n",
    "candidates_gdf.plot(\n",
    "    ax=ax,\n",
    "    column=\"missing_type\",\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    markersize=50,\n",
    "    alpha=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4994805d",
   "metadata": {},
   "source": [
    "##### Add facilities to areas with 4 of 5 POIs covered (Virtual Injection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c67f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy\n",
    "node_to_types_scenario = copy.deepcopy(node_to_types)\n",
    "\n",
    "# Loop through our proposed candidate sites (the new facilities)\n",
    "# Add them to the dictionary that tells us which node has which POI\n",
    "for index, row in candidates_gdf.iterrows():\n",
    "    node_id = row[\"node_id\"]\n",
    "    new_type = row[\"missing_type\"]\n",
    "    \n",
    "    # Check if the node is already in our dictionary\n",
    "    if node_id in node_to_types_scenario:\n",
    "        # Add the new type to the existing set\n",
    "        node_to_types_scenario[node_id].add(new_type)\n",
    "    else:\n",
    "        # Create a new entry for this node\n",
    "        node_to_types_scenario[node_id] = {new_type}\n",
    "\n",
    "print(f\"Added {len(candidates_gdf)} new facilities.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb239364",
   "metadata": {},
   "source": [
    "##### Recalculate network analysis with the new, added facilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edfffbb",
   "metadata": {},
   "source": [
    "Accessibility is recalculated to find how the situation improves through adding the proposed facilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculation of accessibility for scenario\n",
    "\n",
    "print(f\"Calculating scenario accessibility from {len(node_to_types_scenario)} POI nodes...\")\n",
    "\n",
    "node_coverage_scenario = defaultdict(set)\n",
    "\n",
    "for poi_node, poi_types in node_to_types_scenario.items():\n",
    "    try:\n",
    "        lengths = nx.single_source_dijkstra_path_length(\n",
    "            network_graz,\n",
    "            source=poi_node,\n",
    "            weight=\"length\",\n",
    "            cutoff=MAX_DIST,\n",
    "        )\n",
    "        \n",
    "        for reachable_node in lengths.keys():\n",
    "            node_coverage_scenario[reachable_node] |= poi_types\n",
    "            \n",
    "    except nx.NodeNotFound:\n",
    "        print(f\"Warning: POI node {poi_node} not found in network\")\n",
    "        continue\n",
    "\n",
    "node_coverage_scenario = dict(node_coverage_scenario)\n",
    "\n",
    "# Add the new results to our nodes DataFrame\n",
    "nodes_analysis[\"reachable_types_scenario\"] = nodes_analysis.index.map(\n",
    "    lambda n: node_coverage_scenario.get(n, set())\n",
    ")\n",
    "\n",
    "# Check if all 5 required types are present now\n",
    "nodes_analysis[\"has_all_required_scenario\"] = nodes_analysis[\"reachable_types_scenario\"].apply(\n",
    "    lambda s: required_types.issubset(s)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5535a9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define status for comparison\n",
    "\n",
    "# 0 = Still unserved (Bad)\n",
    "# 1 = Baseline (Was already good before)\n",
    "# 2 = New Served (Improvement due to our scenario)\n",
    "\n",
    "def get_status_code(row):\n",
    "    if row[\"has_all_required\"] == True:\n",
    "        return 1\n",
    "    elif row[\"has_all_required_scenario\"] == True:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply this function to every row\n",
    "nodes_analysis[\"scenario_status\"] = nodes_analysis.apply(get_status_code, axis=1)\n",
    "\n",
    "# Show a quick count of how many nodes are in which category\n",
    "print(\"Nodes status breakdown:\")\n",
    "# Rename the codes to text for better readability in the print output\n",
    "print(nodes_analysis[\"scenario_status\"].value_counts().rename({0: \"Unserved\", 1: \"Baseline\", 2: \"New Served\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2621d5b0",
   "metadata": {},
   "source": [
    "##### Fix spatial bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180204e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consistent Interpolation to fix spatial bias (first result had slight deviation between baseline and scenario grids)\n",
    "\n",
    "# we get the target coordinates ONCE\n",
    "# We use the center points (centroids) of the grid cells\n",
    "grid_x = grid_gdf.geometry.centroid.x\n",
    "grid_y = grid_gdf.geometry.centroid.y\n",
    "grid_centroids = np.column_stack((grid_x, grid_y))\n",
    "\n",
    "# 2. Interpolate BOTH states onto these exact coordinates\n",
    "# This guarantees that there is no shift between \"Before\" and \"After\" layers\n",
    "\n",
    "# Re-calculate Baseline (Current State)\n",
    "values_baseline = nodes_analysis[\"has_all_required\"].astype(float)\n",
    "\n",
    "grid_values_baseline = griddata(\n",
    "    points=node_points,       # Source: Street nodes\n",
    "    values=values_baseline,   # Source: Baseline True/False\n",
    "    xi=grid_centroids,        # Target: Grid centers\n",
    "    method=\"nearest\"\n",
    ")\n",
    "\n",
    "# Calculate Scenario (Future State)\n",
    "values_scenario = nodes_analysis[\"has_all_required_scenario\"].astype(float)\n",
    "\n",
    "grid_values_scenario = griddata(\n",
    "    points=node_points,       # Source: Street nodes\n",
    "    values=values_scenario,   # Source: Scenario True/False\n",
    "    xi=grid_centroids,        # Target: Grid centers\n",
    "    method=\"nearest\"\n",
    ")\n",
    "\n",
    "# Save clean boolean values to the grid\n",
    "# We use 0.5 as the threshold (nearest neighbor gives 0.0 or 1.0)\n",
    "grid_gdf[\"served_baseline_clean\"] = (grid_values_baseline >= 0.5)\n",
    "grid_gdf[\"served_scenario_clean\"] = (grid_values_scenario >= 0.5)\n",
    "\n",
    "# Calculate the Map Status (0, 1, 2)\n",
    "# Now we compare the two CLEAN columns. The artifacts should be gone.\n",
    "grid_gdf[\"status_plot\"] = 0  # Default: Unserved\n",
    "\n",
    "# Baseline: Was already served\n",
    "grid_gdf.loc[grid_gdf[\"served_baseline_clean\"] == True, \"status_plot\"] = 1\n",
    "\n",
    "# New Served: Was NOT served before, but IS served now\n",
    "mask_newly_served = (grid_gdf[\"served_baseline_clean\"] == False) & (grid_gdf[\"served_scenario_clean\"] == True)\n",
    "grid_gdf.loc[mask_newly_served, \"status_plot\"] = 2\n",
    "\n",
    "print(\"Interpolation finished. Spatial bias should be removed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab8110c",
   "metadata": {},
   "source": [
    "## Results of the scenario analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6d051f",
   "metadata": {},
   "source": [
    "##### Population and area statistics with the added facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486e21b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population and Area Statistics (Delta Analysis)\n",
    "\n",
    "# Calculate Baseline Population\n",
    "# FIX: We select ONLY geometry and the clean baseline column to avoid duplicates\n",
    "grid_temp_base = grid_gdf[[\"geometry\", \"served_baseline_clean\"]].copy()\n",
    "grid_temp_base = grid_temp_base.rename(columns={\"served_baseline_clean\": \"served\"})\n",
    "\n",
    "# Run the population function for Baseline\n",
    "pop_baseline, share_baseline = pop_disaggregation(POP_GRAZ_PATH, grid_temp_base)\n",
    "\n",
    "# Calculate Scenario Population\n",
    "# FIX: We select ONLY geometry and the clean scenario column\n",
    "grid_temp_scen = grid_gdf[[\"geometry\", \"served_scenario_clean\"]].copy()\n",
    "grid_temp_scen = grid_temp_scen.rename(columns={\"served_scenario_clean\": \"served\"})\n",
    "\n",
    "# Run the population function for Scenario\n",
    "pop_scenario, share_scenario = pop_disaggregation(POP_GRAZ_PATH, grid_temp_scen)\n",
    "\n",
    "# Calculate the Difference\n",
    "pop_diff = pop_scenario - pop_baseline\n",
    "\n",
    "print(f\"--- RESULTS (Bias Corrected) ---\")\n",
    "print(f\"Population served (Baseline): {pop_baseline:,.0f} ({share_baseline:.2%})\")\n",
    "print(f\"Population served (Scenario): {pop_scenario:,.0f} ({share_scenario:.2%})\")\n",
    "print(f\"IMPACT: +{pop_diff:,.0f} people gained access!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e706536b",
   "metadata": {},
   "source": [
    "##### Visualizations of the new situation with the added facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfae9ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Visualization: Comparison Map with Custom Colors\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Background Grid (Area Status)\n",
    "grid_colors = [\"#bda1a1\", '#a6cee3', \"#71c925\"] \n",
    "cmap_grid = ListedColormap(grid_colors)\n",
    "\n",
    "grid_gdf.plot(\n",
    "    column=\"status_plot\",\n",
    "    cmap=cmap_grid,\n",
    "    ax=ax,\n",
    "    edgecolor=\"none\",\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "# City Boundary\n",
    "\n",
    "gdf_graz.boundary.plot(ax=ax, color=\"black\", linewidth=1.5, zorder=5)\n",
    "\n",
    "# New Facilities (Candidates) with Custom Colors\n",
    "\n",
    "type_colors = {\n",
    "    \"green_space\": \"forestgreen\",\n",
    "    \"shop\": \"blue\",\n",
    "    \"doctor\": \"crimson\",\n",
    "    \"pharmacy\": \"magenta\",\n",
    "    \"public_transport\": \"orange\"\n",
    "}\n",
    "\n",
    "\n",
    "for m_type, data_subset in candidates_gdf.groupby(\"missing_type\"):\n",
    "    \n",
    "    my_color = type_colors.get(m_type, \"black\")\n",
    "    \n",
    "    data_subset.plot(\n",
    "        ax=ax,\n",
    "        color=my_color,\n",
    "        markersize=100,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1,\n",
    "        zorder=10,\n",
    "        label=m_type\n",
    "    )\n",
    "\n",
    "# LEGEND 1: Facilities\n",
    "first_legend = ax.legend(loc='upper right', title=\"New Facilities\")\n",
    "ax.add_artist(first_legend) # IMPORTANT: Add it back, because the next legend would overwrite it\n",
    "\n",
    "# LEGEND 2: Area Status\n",
    "patch_grey  = mpatches.Patch(color='#bda1a1', label='Still Unserved')\n",
    "patch_blue  = mpatches.Patch(color='#a6cee3', label='Baseline (Existing)')\n",
    "patch_green = mpatches.Patch(color=\"#71c925\", label='Scenario Impact (New)')\n",
    "ax.legend(handles=[patch_grey, patch_blue, patch_green], loc='lower right', title=\"Area Coverage\")\n",
    "plt.title(f\"Scenario Analysis: By adding {len(candidates_gdf)} facilities, {pop_diff:,.0f} people gain access to a 15-min City\", fontsize=15)\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / \"scenario_analysis_map.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-gst200b311 (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
